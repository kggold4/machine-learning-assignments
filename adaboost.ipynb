{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "> Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data2():\n",
    "    points=[]\n",
    "    with open('data/four_circle.txt', 'r') as text:\n",
    "        for line in text.readlines():\n",
    "            _x, _y, _label = line.split()\n",
    "            #lines.append(Line())\n",
    "            points.append(Point(float(_x),float(_y),int(_label)))\n",
    "    points=np.array(points)\n",
    "    lines=create_lines(points)\n",
    "    return points,lines\n",
    "\n",
    "def create_lines(points):\n",
    "    lines=[]\n",
    "    for i in range(len(points)):\n",
    "        p1=points[i]\n",
    "        for j in range(i+1,len(points)):\n",
    "            p2=points[j]\n",
    "            lines.append(Line(p1,p2,1))\n",
    "            lines.append(Line(p1,p2,-1))\n",
    "    return np.array(lines)\n",
    "\n",
    "def split_data(points: list):\n",
    "    \"\"\"\n",
    "    splits the data into train and test //maybe wil be depraceted later\n",
    "    :param points: list of data points\n",
    "    :return: train & test groups.\n",
    "    \"\"\"\n",
    "    return train_test_split(points, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point:\n",
    "    def __init__(self, x: float, y: float, label: int):\n",
    "        \"\"\"\n",
    "        :param x: X-axis\n",
    "        :param y: Y-axis\n",
    "        :param label: The given data point label\n",
    "        \"\"\"\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.label = label\n",
    "        self.w = 0\n",
    "\n",
    "#     def toArray(self):\n",
    "#         \"\"\"\n",
    "#         This function converts a single data point into array: [x, y, label]\n",
    "#         :return: array\n",
    "#         \"\"\"\n",
    "#         return [self.x, self.y, self.label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line:\n",
    "    def __init__(self, p1: Point, p2: Point, direct: int):\n",
    "        \"\"\"\n",
    "        - Rule: y=ax+b\n",
    "        :param point: Single point for computing line equation.\n",
    "        :param coefficient: a\n",
    "        :param bias: b\n",
    "        \"\"\"\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "        #self.a = (self.p1.y - self.p2.y)\n",
    "        self.x=self.p1.x-self.p2.x\n",
    "        self.y=self.p1.y-self.p2.y\n",
    "#         self.b = (self.p2.x - self.p1.x)\n",
    "#         self.c = (self.p1.x * self.p2.y - self.p2.x * self.p1.y)\n",
    "        self.direct = direct\n",
    "        self.w=0\n",
    "\n",
    "    def eval(self, p: Point):\n",
    "        \"\"\"\n",
    "        we will use the following equation to determine the label of a point\n",
    "        value = (x1 - x0)(y2 - y0) - (x2 - x0)(y1 - y0)\n",
    "        if value > 0, p2 is on the left side of the line.\n",
    "        if value = 0, p2 is on the same line.\n",
    "        if value < 0, p2 is on the right side of the line.\n",
    "        :return: eval\n",
    "        \"\"\"\n",
    "        if self.x*(p.x-self.p2.x)-(p.x-self.p2.x)*self.y>=0:\n",
    "            return self.direct\n",
    "        else:\n",
    "            return -self.direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(lines: list, point: Point):\n",
    "    \"\"\"\n",
    "    This function predicts the true label of a points based\n",
    "    on the rules given with their corresponding weights\n",
    "    Hk(X) from the presentation\n",
    "    \"\"\"\n",
    "    sum = 0\n",
    "    for h in lines:\n",
    "        sum += h.w * h.eval(point)\n",
    "    return 1 if sum > 0 else -1\n",
    "\n",
    "\n",
    "def point_error(lines: list, point: Point):\n",
    "    \"\"\"\n",
    "    This function calculates the error on given point with a given set of rules\n",
    "    \"\"\"\n",
    "    return 1 if predict(lines, point) != point.label else 0\n",
    "\n",
    "\n",
    "def list_error(lines: list, pnts: list):\n",
    "    \"\"\"\n",
    "      This function calculates the error on given points\n",
    "      :param rules_with_weights: list of important rules.\n",
    "      :param l: list of data points (training set)\n",
    "      :return: total error\n",
    "      \"\"\"\n",
    "    total_error = 0\n",
    "   # positive_error_sum = 0\n",
    "#     positive_count = 0\n",
    "#     negative_error_sum = 0\n",
    "#     negative_count = 0\n",
    "\n",
    "    for p in pnts:\n",
    "        error = point_error(lines, p)\n",
    "        total_error += error\n",
    "\n",
    "    return total_error / len(points)\n",
    "\n",
    "\n",
    "def calculate_error(lines: list, train: list, test: list, iterations: int):\n",
    "    \"\"\"\n",
    "    This function calculates the empirical error on the training and test sets.\n",
    "    :param rules_with_weights: list of important rules.\n",
    "    :param train: list of data points (training set)\n",
    "    :param test: list of data points (testing set)\n",
    "    :param iterations: number of iterations for computing the empirical errors\n",
    "    :return: lists of empirical errors on the training and testing set over k iterations.\n",
    "    - NOTE: This function was CHANGED!\n",
    "    \"\"\"\n",
    "    #train_errors, test_errors = ([] for _ in range(2))\n",
    "    tr_errors = []\n",
    "    te_errors = []\n",
    "    iterations = len(lines) if iterations > len(lines) else iterations\n",
    "\n",
    "    for i in range(iterations):\n",
    "        tr_errors.append(list_error(lines[:i + 1], train))\n",
    "        te_errors.append(list_error(lines[:i + 1], test))\n",
    "    return tr_errors, te_errors\n",
    "\n",
    "\n",
    "def run(points: list, rules: list, iterations: int):\n",
    "    \"\"\"\n",
    "    This function simulates a single run of Adaboost algorithm.\n",
    "    :param points: list of data points\n",
    "    :param iterations: number of iterations to perform the algorithm.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    train, test = split_data(points)\n",
    "    for pt in train:\n",
    "        pt.w = 1 / len(train)  # Initialize point weights\n",
    "    min_lines = []\n",
    "    for i in range(iterations):\n",
    "        min_error = np.inf  # Find the min error each iteration and the classifier.\n",
    "        min_clfs = []\n",
    "        for h in rules:\n",
    "            error = 0\n",
    "            for pt in train:\n",
    "                # step 3 , caculate weighted error\n",
    "                if h.eval(pt) != pt.label:\n",
    "                    error += pt.w\n",
    "\n",
    "            if len(min_clfs) == 0 or error <= min_error:  # Find min. error classifier step 4\n",
    "                if error != min_error:  # if its smaller than the current min classifier then change it\n",
    "                    min_error = error\n",
    "                    min_clfs.clear()\n",
    "                min_clfs.append(h)\n",
    "\n",
    "        clf_weight = 0.5*np.log((1 - min_error) / min_error)  # Update classifier weight based on error , step 5\n",
    "        Zt = 0\n",
    "        min_clf = min_clfs[0] #get the best classifier#random.choice(min_classifiers)\n",
    "\n",
    "        for pt in train:\n",
    "            # Calculate the normalizing constant (Zt) step 5.5 and update all the points weights\n",
    "            pt.w = pt.w * (np.e ** (clf_weight * min_clf.eval(pt) * pt.label))\n",
    "            Zt += pt.w\n",
    "        for pt in train:\n",
    "            pt.w = pt.w / Zt\n",
    "        min_clf.w=clf_weight\n",
    "        min_lines.append(min_clf)\n",
    "    return calculate_error(lines, train, test, iterations)\n",
    "\n",
    "    # TODO - Return the empirical error of the function H on the training set and on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "points, lines = read_data2()\n",
    "#lines = create_lines(points)\n",
    "iterations = 8\n",
    "rounds = 100\n",
    "error_means_train=[]\n",
    "error_means_test=[]\n",
    "train_errors= np.zeros(shape=(rounds,iterations))\n",
    "test_errors = np.zeros(shape=(rounds,iterations))\n",
    "# train_errors = [[0 for i in range(rounds)] for j in range(iterations)]\n",
    "# train_errors_pos = [[0 for i in range(rounds)] for j in range(iterations)]\n",
    "# train_errors_neg = [[0 for i in range(rounds)] for j in range(iterations)]\n",
    "\n",
    "# test_errors = [[0 for i in range(rounds)] for j in range(iterations)]\n",
    "# test_errors_pos = [[0 for i in range(rounds)] for j in range(iterations)]\n",
    "# test_errors_neg = [[0 for i in range(rounds)] for j in range(iterations)]\n",
    "\n",
    "for i in range(rounds):\n",
    "    train_error, test_error = run(points, lines, iterations)\n",
    "    error_means_train.append(np.mean(train_error))\n",
    "    error_means_test.append(np.mean(test_error))\n",
    "    \n",
    "#     print(len(train_error))\n",
    "#     print(len(test))\n",
    "\n",
    "   # for j in range(iterations):\n",
    "        #train_errors[i][j] = train_error[j][0]\n",
    "        #    error_means_train.append(np.mean(train_error))\n",
    "#         train_errors_pos[j][i] = train_error[j][1]\n",
    "#         train_errors_neg[j][i] = train_error[j][2]\n",
    "       # error_means_test.append(np.mean(test_error))\n",
    "        #test_errors[i][j] = test_error[j][0]\n",
    "#         test_errors_pos[j][i] = test_error[j][1]\n",
    "#         test_errors_neg[j][i] = test_error[j][2]\n",
    "\n",
    "    # print(i)\n",
    "\n",
    "print(\"error\")\n",
    "for i in range(iterations):\n",
    "    print(f\"k = {i + 1}\",\n",
    "          \"train error: \", \"%.3f\" % error_means_train[i],\n",
    "          \"test error: \", \"%.3f\" % error_means_test[i])\n",
    "# def generate_data_lists(points: list, lines: list):\n",
    "#     \"\"\"\n",
    "#     This function receives a list of data points and converts it to 4 different lists:\n",
    "#     - X and Y list of data points for each label.\n",
    "#     :param points: list of data points to convert\n",
    "#     :return: the generated lists\n",
    "#     \"\"\"\n",
    "#     x1, y1, x2, y2 = ([] for _ in range(4))\n",
    "#     for pt in points:\n",
    "#         if pt.label != predict_value(lines, pt):\n",
    "#             x1.append(pt.x)\n",
    "#             y1.append(pt.y)\n",
    "#         else:\n",
    "#             x2.append(pt.x)\n",
    "#             y2.append(pt.y)\n",
    "#     return x1, y1, x2, y2\n",
    "\n",
    "\n",
    "# def represent_data_points(points: list, rules_with_weights: list):\n",
    "#     \"\"\"\n",
    "#     This function plots the data points.\n",
    "#     :param points: list of data points to plot.\n",
    "#     :return: None\n",
    "#     \"\"\"\n",
    "#     x1, y1, x2, y2 = generate_data_lists(points, rules_with_weights)\n",
    "#     plt.scatter(x1, y1, color='red')\n",
    "#     plt.scatter(x2, y2, color='blue')\n",
    "\n",
    "#     for rule in lines:\n",
    "#         r = rule\n",
    "#         plt.plot([r.p1.x, r.p1.y], [r.p2.x, r.p2.y], marker='o')\n",
    "\n",
    "#     # TODO - Add classifier lines\n",
    "\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62cf12e785b3c02d23b2799d6a94df39832e95b106b2936bc46e43c4c157bc39"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
